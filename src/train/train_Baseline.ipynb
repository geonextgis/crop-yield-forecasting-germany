{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45f7295",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888bf9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "source_folder = \"/beegfs/halder/GITHUB/RESEARCH/crop-yield-forecasting-germany/src\"\n",
    "sys.path.append(source_folder)\n",
    "\n",
    "import config.winter_wheat as cfg\n",
    "import numpy as np\n",
    "import torch\n",
    "from config.winter_wheat import model_config, train_config\n",
    "from dataset.dataset import CropFusionNetDataset\n",
    "from loss.loss import QuantileLoss\n",
    "from models.AttnLSTM.model import AttnLSTM\n",
    "from models.ResCNN.model import ResCNN\n",
    "from models.SimpleTransformer.model import SimpleTransformer\n",
    "from models.VanillaLSTM.model import VanillaLSTM\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from utils.utils import set_seed, evaluate_and_save_outputs, load_config, save_config\n",
    "\n",
    "# Crop\n",
    "crop = \"winter_barley\"\n",
    "cfg, model_config, train_config = load_config(crop)\n",
    "\n",
    "device = model_config[\"device\"]\n",
    "set_seed(42)\n",
    "baseline_model_name = \"ResCNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d662f",
   "metadata": {},
   "source": [
    "## Create datasets and dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e51008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CropFusionNetDataset(cfg, mode=\"train\", scale=True)\n",
    "val_dataset = CropFusionNetDataset(cfg, mode=\"val\", scale=True)\n",
    "test_dataset = CropFusionNetDataset(cfg, mode=\"test\", scale=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=32,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=train_config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=32,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=train_config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be02d77",
   "metadata": {},
   "source": [
    "## Model, optimizer and loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7daa08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ResCNN(model_config).to(device)\n",
    "criterion = QuantileLoss(quantiles=model_config[\"quantiles\"]).to(device)\n",
    "optimizer = Adam(\n",
    "    model.parameters(), lr=train_config[\"lr\"], weight_decay=train_config[\"weight_decay\"]\n",
    ")\n",
    "num_epochs = train_config.get(\"num_epochs\", 50)\n",
    "patience = train_config.get(\"early_stopping_patience\", 10)\n",
    "batch_size = train_config.get(\"batch_size\", 32)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",  # minimize validation loss\n",
    "    factor=0.5,  # reduce LR by 50%\n",
    "    patience=3,  # wait for 3 epochs before reducing\n",
    "    threshold=1e-4,  # minimal improvement threshold\n",
    "    min_lr=1e-6,  # lower bound for learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f77fb",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d10d2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    patience,\n",
    "    scheduler=None,\n",
    "    checkpoint_dir=\"checkpoints\",\n",
    "    exp_name=\"CropFusionNet_experiment\",\n",
    "):\n",
    "    # 1. Setup Logging\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_id = f\"run_{exp_name}_{timestamp}\"\n",
    "    log_dir = os.path.join(\"runs\", log_id)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    save_folder = os.path.join(checkpoint_dir, log_id)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    print(f\"üìò TensorBoard logs: {log_dir}\")\n",
    "    print(f\"üíæ Checkpoints: {save_folder}\")\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # --- TRAINING PHASE ---\n",
    "        model.train()\n",
    "        train_loss_accum = 0.0\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n",
    "        for batch in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move inputs to device\n",
    "            inputs = {\n",
    "                \"inputs\": batch[\"inputs\"].to(device),\n",
    "                \"identifier\": batch[\"identifier\"].to(device),\n",
    "                \"mask\": batch[\"mask\"].to(device),\n",
    "                \"variable_mask\": (\n",
    "                    batch.get(\"variable_mask\").to(device)\n",
    "                    if batch.get(\"variable_mask\") is not None\n",
    "                    else None\n",
    "                ),\n",
    "            }\n",
    "            targets = batch[\"target\"].to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            output_dict = model(inputs)\n",
    "            preds = output_dict[\"prediction\"]\n",
    "\n",
    "            # Loss Calculation\n",
    "            loss = criterion(preds, targets)\n",
    "\n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient Clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "\n",
    "            # Optimization Step\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_accum += loss.item()\n",
    "            train_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_train_loss = train_loss_accum / len(train_loader)\n",
    "\n",
    "        # --- VALIDATION PHASE ---\n",
    "        model.eval()\n",
    "        val_loss_accum = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs = {\n",
    "                    \"inputs\": batch[\"inputs\"].to(device),\n",
    "                    \"identifier\": batch[\"identifier\"].to(device),\n",
    "                    \"mask\": batch[\"mask\"].to(device),\n",
    "                    \"variable_mask\": (\n",
    "                        batch.get(\"variable_mask\").to(device)\n",
    "                        if batch.get(\"variable_mask\") is not None\n",
    "                        else None\n",
    "                    ),\n",
    "                }\n",
    "                targets = batch[\"target\"].to(device)\n",
    "\n",
    "                output_dict = model(inputs)\n",
    "                preds = output_dict[\"prediction\"]\n",
    "\n",
    "                loss = criterion(preds, targets)\n",
    "                val_loss_accum += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss_accum / len(val_loader)\n",
    "\n",
    "        # --- LOGGING & SCHEDULING ---\n",
    "        elapsed = time.time() - start_time\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | Train: {avg_train_loss:.4f} | Val: {avg_val_loss:.4f} | LR: {current_lr:.2e} | T: {elapsed:.1f}s\"\n",
    "        )\n",
    "\n",
    "        writer.add_scalars(\n",
    "            \"Loss\", {\"Train\": avg_train_loss, \"Val\": avg_val_loss}, epoch\n",
    "        )\n",
    "        writer.add_scalar(\"LR\", current_lr, epoch)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early Stopping\n",
    "        if avg_val_loss < best_val_loss - 1e-4:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save(best_model_state, os.path.join(save_folder, \"best_model.pt\"))\n",
    "            print(f\"‚ú® New best model saved.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"‚èπÔ∏è Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    writer.close()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "662474f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò TensorBoard logs: runs/run_exp_winter_barley_Jul_ResCNN_Baseline_20260301-113405\n",
      "üíæ Checkpoints: checkpoints/run_exp_winter_barley_Jul_ResCNN_Baseline_20260301-113405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:04<00:00,  9.44it/s, loss=0.5911]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train: 0.6724 | Val: 0.7464 | LR: 1.00e-04 | T: 7.5s\n",
      "‚ú® New best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:04<00:00, 11.29it/s, loss=0.4895]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Train: 0.5572 | Val: 0.6966 | LR: 1.00e-04 | T: 5.5s\n",
      "‚ú® New best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.03it/s, loss=0.5635]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Train: 0.5338 | Val: 0.6462 | LR: 1.00e-04 | T: 5.3s\n",
      "‚ú® New best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 11.78it/s, loss=0.4871]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Train: 0.5166 | Val: 0.6208 | LR: 1.00e-04 | T: 5.3s\n",
      "‚ú® New best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 11.95it/s, loss=0.4662]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Train: 0.5033 | Val: 0.6254 | LR: 1.00e-04 | T: 5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.20it/s, loss=0.4712]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Train: 0.4904 | Val: 0.6479 | LR: 1.00e-04 | T: 5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 11.93it/s, loss=0.5461]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Train: 0.4811 | Val: 0.6660 | LR: 1.00e-04 | T: 5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.09it/s, loss=0.4487]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Train: 0.4699 | Val: 0.6265 | LR: 1.00e-04 | T: 5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.31it/s, loss=0.4351]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Train: 0.4551 | Val: 0.6165 | LR: 5.00e-05 | T: 5.1s\n",
      "‚ú® New best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.36it/s, loss=0.4598]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Train: 0.4534 | Val: 0.6533 | LR: 5.00e-05 | T: 5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.24it/s, loss=0.5295]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Train: 0.4484 | Val: 0.6306 | LR: 5.00e-05 | T: 5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.37it/s, loss=0.4802]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Train: 0.4466 | Val: 0.6399 | LR: 5.00e-05 | T: 5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.32it/s, loss=0.3549]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Train: 0.4380 | Val: 0.6510 | LR: 5.00e-05 | T: 5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.47it/s, loss=0.3996]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Train: 0.4301 | Val: 0.6516 | LR: 2.50e-05 | T: 5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 11.99it/s, loss=0.4471]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Train: 0.4278 | Val: 0.6386 | LR: 2.50e-05 | T: 5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.01it/s, loss=0.4437]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Train: 0.4241 | Val: 0.6531 | LR: 2.50e-05 | T: 5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 11.99it/s, loss=0.3945]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Train: 0.4220 | Val: 0.6445 | LR: 2.50e-05 | T: 5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 11.79it/s, loss=0.3807]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Train: 0.4218 | Val: 0.6417 | LR: 1.25e-05 | T: 5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/500 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 11.83it/s, loss=0.4932]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Train: 0.4214 | Val: 0.6705 | LR: 1.25e-05 | T: 5.4s\n",
      "‚èπÔ∏è Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6165075855595725"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    patience,\n",
    "    scheduler,\n",
    "    exp_name=f\"{train_config[\"exp_name\"]}_{baseline_model_name}_Baseline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54563f85",
   "metadata": {},
   "source": [
    "## Save the trained model, config, and the outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1033c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Trained model saved to /beegfs/halder/GITHUB/RESEARCH/crop-yield-forecasting-germany/src/train/baseline/winter_barley/Jul/ResCNN/best_model.pt\n",
      "üîç Evaluating and saving outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [00:03<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4163\n",
      "Outputs saved to: /beegfs/halder/GITHUB/RESEARCH/crop-yield-forecasting-germany/src/train/baseline/winter_barley/Jul/ResCNN/train_outputs.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6705\n",
      "Outputs saved to: /beegfs/halder/GITHUB/RESEARCH/crop-yield-forecasting-germany/src/train/baseline/winter_barley/Jul/ResCNN/validation_outputs.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6995\n",
      "Outputs saved to: /beegfs/halder/GITHUB/RESEARCH/crop-yield-forecasting-germany/src/train/baseline/winter_barley/Jul/ResCNN/test_outputs.pkl\n",
      "Config saved to: /beegfs/halder/GITHUB/RESEARCH/crop-yield-forecasting-germany/src/train/baseline/winter_barley/Jul/ResCNN/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "output_dir = os.path.join(\n",
    "    source_folder, \"train\", \"baseline\", crop, cfg.forecast_month, baseline_model_name\n",
    ")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_save_path = os.path.join(output_dir, f\"best_model.pt\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"üíæ Trained model saved to {model_save_path}\")\n",
    "\n",
    "# Save outputs\n",
    "print(\"üîç Evaluating and saving outputs...\")\n",
    "\n",
    "# Evaluate and save outputs for train, validation, and test datasets\n",
    "evaluate_and_save_outputs(model, train_loader, criterion, device, output_dir, \"train\")\n",
    "evaluate_and_save_outputs(\n",
    "    model, val_loader, criterion, device, output_dir, \"validation\"\n",
    ")\n",
    "evaluate_and_save_outputs(model, test_loader, criterion, device, output_dir, \"test\")\n",
    "\n",
    "# Save the model config\n",
    "save_config(train_config, model_config, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
